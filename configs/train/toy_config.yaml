# configs/train/train_digicam_quick.yaml
# Быстрый прогон DigiCam: 100 файлов, 2 эпохи, один GPU

seed: 0

files:
  # Hugging Face датасет DigiCam MIRFlickr (25k пар "lensless↔lensed")
  dataset: bezzam/DigiCam-Mirflickr-SingleMask-25K
  split: train             # использовать обучающую часть датасета
  n_files: 100             # <<< ограничение на число примеров для быстрой проверки
  test_size: 0.1           # 10% пойдут под валидацию внутри запуска
  cache_dir: null          # можно указать путь (напр., /dev/shm или /tmp/hf_cache)
  # Для DigiCam часто используют симулированный/заданный PSF-файл (см. примеры в слепках Hydra):
  huggingface_psf: psf_simulated_waveprop.png   # имя файла PSF в пакете моделей/ресурсов
  downsample: 2            # при необходимости уменьшить размер входа (ускоряет обучение)
  torch: true
  torch_device: cuda:0     # поменяй на "cpu", если без GPU
  vertical_shift: null
  horizontal_shift: null
  crop: null               # [h,w], если нужно обрезать (оставь null для авто)
  input_snr: 0.0           # без добавления шума на вход
  diffcam_compat: false    # специальный флаг не нужен; оставляем false
  eval_disp_idx: [0, 1, 2, 3, 4]
  test_idx:       [0, 1, 2, 3, 4]

display:
  plot: true
  gamma: null
  save: true               # сохранять выборочные результаты/выводы модели

reconstruction:
  # Минимальная рабочая сборка: unrolled ADMM + постпроцессор U-Net-подобный
  method: unrolled_admm
  skip_unrolled: false

  unrolled_admm:
    n_iter: 5              # небольшое число итераций для скорости
    mu1: 1.0e-6
    mu2: 1.0e-5
    mu3: 4.0e-5
    tau: 1.0e-4
    learn_params: true     # разрешим учить параметры алгоритма, если реализовано

  # Предобработчик (опционально). Для быстрого прогона не используем.
  pre_process:
    network: null
    nc: null
    depth: 0
    delay: null
    freeze: null
    unfreeze: null

  # Постобработчик — компактная U-Net-подобная сеть
  post_process:
    network: UnetRes       # имя совпадает с примерами в репозитории
    nc: [32, 64, 128, 256] # каналы по уровням
    depth: 4
    train_last_layer: false
    delay: null
    freeze: null
    unfreeze: null

# Симуляция нам не нужна (мы берём реальные измерения DigiCam), оставим по умолчанию
simulation:
  grayscale: false
  output_dim: null
  object_height: null
  flip: false
  random_shift: false
  random_vflip: 0.0
  random_hflip: 0.0
  random_rotate: false
  scene2mask: null
  mask2sensor: null
  sensor: null
  snr_db: 0.0
  downsample: 1
  quantize: false
  max_val: 255

training:
  epoch: 2                 # всего 2 эпохи — хватит, чтобы убедиться что всё работает
  batch_size: 4
  eval_batch_size: 4
  metric_for_best_model: PSNR
  save_every: 1
  skip_NAN: true
  clip_grad: 1.0
  crop_preloss: false

optimizer:
  type: Adam
  lr: 1.0e-4
  weight_decay: 0.0
  # Без сложных расписаний для простоты:
  step: false
  gamma: 0.9
  cosine_decay_warmup: false
  warmup_epochs: 0

# Суммарный лосс: просто L2 (можно позже добавить LPIPS, задать вес)
loss: l2
lpips: 0.0
unrolled_output_factor: 0.0

# Логирование (можно подключить W&B проект)
wandb_project: true
